# RAG-пайплайн для VK

## Оглавление

* [1. Подготовка: получение сервисного ключа VK](#1-подготовка-получение-сервисного-ключа-vk)
* [2. Установка библиотеки VK API](#2-установка-библиотеки-для-работы-с-vk-api)
* [3. Подготовка данных для RAG](#3-следующий-этап-подготовка-данных-для-rag)
* [4. Установка зависимостей для RAG](#4-установка-зависимостей-для-rag)
* [5. Скрипт подготовки векторной базы](#5-скрипт-подготовки-векторной-базы)
* [6. Готовая ChromaDB](#6-готовая-chromadb)
* [7. Подключение Google Gemini](#7-подключение-google-gemini-через-langchain)
* [8. Возможные улучшения](#8-возможные-улучшения)

--- для VK: Полное руководство

Ниже приведена структурированная и читабельная версия инструкции по сбору данных из ВК, подготовке их для RAG и подключению LLM.

---

## 1. Подготовка: получение сервисного ключа VK: получение сервисного ключа VK

1. Перейдите на **dev.vk.com**.
2. Создайте новое приложение.
3. Откройте раздел **Настройки → Сервисный ключ доступа**.
4. Скопируйте полученный длинный токен.

---

## 2. Установка библиотеки для работы с VK API

Используется библиотека `vk_api`:

```bash
# Установка зависимости
pip install vk_api
```

**Зачем используется:**

* `marked_as_ads` — позволяет исключить рекламные посты.
* Очистка вики-разметки — удаление типа `[id123|Имя]` → `Имя`.
* Добавление метаданных: `url`, `likes`, `date`.

Это важно для дальнейшего RAG:

* **url** — для ссылок на источник,
* **likes** — для фильтрации низкокачественного контента.

---

## 3. Следующий этап: подготовка данных для RAG: подготовка данных для RAG

После выгрузки JSON (`vk_dataset.json`) необходимо:

### 3.1. Чанкинг (Chunking)

Разделение длинных постов на смысловые части.

* **Размер чанка**: ~1000 символов.
* **Overlap**: ~200 символов.

### 3.2. Эмбеддинг (Vectorization)

Преобразование текста в векторы.
Рекомендуемые модели:

* `intfloat/multilingual-e5-large`
* `ru-en-roberta`

### 3.3. Сохранение в векторную базу

Обычно используется:

* **ChromaDB** (simple, локально)
* **FAISS**
* **Pinecone**

---

## 4. Установка зависимостей для RAG

Устанавливаем LangChain, ChromaDB и модели эмбеддингов:

```bash
# Установка зависимости
pip install langchain langchain-community langchain-huggingface chromadb sentence-transformers
```

---

## 5. Скрипт подготовки векторной базы

Этот этап включает:

1. Загрузку JSON.
2. Превращение в список документов LangChain.
3. Чанкинг.
4. Создание эмбеддингов (`paraphrase-multilingual-MiniLM-L12-v2`).
5. Сохранение данных в `vk_vector_db/`.

**Почему именно эта модель:**

* мультиязычная,
* хорошо понимает русский,
* выдаёт 384-мерные векторы.

### Важность метаданных

Сохраняем:

* `url`,
* `likes`,
* `date`.

Это позволяет:

* возвращать источник,
* фильтровать шум.

---

## 6. Готовая ChromaDB

Папка `vk_vector_db` — это итоговая база знаний паблика.

Далее подключается LLM, которая:

1. Принимает вопрос пользователя.
2. Ищет по базе (similarity search).
3. Формирует ответ.

---

## 7. Подключение Google Gemini через LangChain

### 7.1. Получение API-ключа

1. Перейти на **aistudio.google.com**.
2. Нажать **Get API key → Create API key**.
3. Сохранить ключ.

### 7.2. Установка зависимостей

```bash
# Установка зависимости
pip install langchain-google-genai
```

### 7.3. Финальный RAG-скрипт

Этот код объединяет:

* загрузку базы,
* поиск релевантных чанков,
* генерацию ответа через LLM.

---

## 8. Возможные улучшения

### 8.1. Память диалога

Добавить `ConversationBufferMemory` в LangChain.

### 8.2. Использование отечественной модели (пример: GigaChat)

```python
from langchain_community.chat_models import GigaChat
llm = GigaChat(credentials="ТОКЕН", verify_ssl_certs=False)
```

---

---

## Итог

Этот README теперь отражает полный рабочий процесс:

* получение данных из ВК,
* очистка,
* чанкинг,
* создание векторной БД,
* подключение LLM,
* рекомендации по улучшению.

Структура оптимизирована для практического использования в RAG-системах.
